{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalMemory(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_categories,\n",
    "                 num_attributes_per_category,\n",
    "                 categories_key_size=64,\n",
    "                 attributes_key_size=64,\n",
    "                 value_size=64,\n",
    "                 dropout=0.1,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_categories = num_categories\n",
    "        self.num_attributes_per_category = num_attributes_per_category\n",
    "        \n",
    "        self.categories_key_size = categories_key_size\n",
    "        self.attributes_key_size = attributes_key_size\n",
    "        self.value_size = value_size\n",
    "        \n",
    "        self.categories = torch.FloatTensor(num_categories, categories_key_size)\n",
    "        self.attributes = torch.FloatTensor(num_categories, num_attributes_per_category, attributes_key_size)\n",
    "        \n",
    "        self.categories = nn.Parameter(self.categories)\n",
    "        self.attributes = nn.Parameter(self.attributes)\n",
    "        \n",
    "        if value_size is not None:\n",
    "            self.values = torch.FloatTensor(num_categories, num_attributes_per_category, value_size)\n",
    "            self.values = nn.Parameter(self.values)\n",
    "        else:\n",
    "            self.values = None\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self._init_params()\n",
    "        \n",
    "    def _init_params(self):\n",
    "        nn.init.normal_(self.categories)\n",
    "        nn.init.normal_(self.attributes)\n",
    "        if self.values is not None:\n",
    "            nn.init.normal_(self.values)\n",
    "        \n",
    "    def forward(self, query):\n",
    "        \n",
    "        query = self.dropout(query)\n",
    "        category_attention = torch.matmul(query[:, :self.categories_key_size], self.categories.t())\n",
    "        category_attention = nn.functional.softmax(category_attention, dim=1)\n",
    "                \n",
    "        attribute_attention = torch.matmul(query[:, self.categories_key_size:], self.attributes.permute(0, 2, 1))\n",
    "        attribute_attention = nn.functional.softmax(attribute_attention, dim=2)\n",
    "                \n",
    "        if self.values is not None:\n",
    "            attribute_attention = torch.matmul(attribute_attention, self.values)\n",
    "\n",
    "        else:\n",
    "            attribute_attention = torch.matmul(attribute_attention, self.attributes)\n",
    "        \n",
    "        category_attention = torch.matmul(category_attention.unsqueeze(1), attribute_attention).squeeze(1)\n",
    "        \n",
    "        return category_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mac import HierarchicalMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9812, -1.2954,  0.1503,  0.1214,  2.4526, -0.2100,  0.6897, -0.3006])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4126,  0.6920,  0.2098, -0.2235, -0.3082,  0.2059,  0.4995,\n",
       "           0.1840],\n",
       "         [-0.8027, -0.1491, -0.2894, -0.7281,  0.5694, -0.1165, -0.1300,\n",
       "          -0.0618],\n",
       "         [-0.5812,  1.0318, -0.1973, -0.1821, -0.3681, -0.3152, -0.9683,\n",
       "          -0.3389],\n",
       "         [ 0.3253,  0.0450, -0.0862, -0.0870, -0.3185,  0.1147,  0.0950,\n",
       "          -0.5925],\n",
       "         [ 0.4874, -0.6049, -0.0925,  0.0021,  0.3434,  0.9950, -0.0963,\n",
       "           0.3307]],\n",
       "\n",
       "        [[-0.4825, -0.1253, -0.1234, -0.1229,  0.3158, -0.5058, -0.2277,\n",
       "           0.6234],\n",
       "         [-1.0779, -0.6746, -0.4625,  0.3930, -0.2796, -0.1995, -0.3210,\n",
       "          -0.5292],\n",
       "         [-0.5685,  1.2189,  0.1967,  0.2939, -0.1047,  0.0913, -1.1220,\n",
       "          -0.4336],\n",
       "         [ 0.2339, -0.0343,  0.0202, -0.9019, -0.5439,  0.3890,  0.2416,\n",
       "          -0.6860],\n",
       "         [ 0.7302, -0.9310,  0.3548,  0.2108, -0.2683,  0.9025, -0.1845,\n",
       "           0.1122]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nn.functional.softmax(torch.randn(2, 5, 6), dim=2).unsqueeze(3) *  torch.randn(5, 6, 8)).sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([3, 4, 2])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1142, -0.0093,  1.2074,  0.8915, -0.6113,  0.2692],\n",
       "        [-0.0981,  1.2242, -0.0969,  0.5737,  0.4226, -0.1635]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm = HierarchicalMemory(3, 4, 5, 6, value_size=None)\n",
    "attributes, categories = hm.attributes, hm.categories\n",
    "# print(categories), print(attributes);\n",
    "hm(torch.ones(2, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchsummaryX import summary\n",
    "\n",
    "\n",
    "from mac import MACNetwork\n",
    "from utils import load_vocab\n",
    "from datasets import ClevrDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import cfg_from_file, __C, cfg\n",
    "\n",
    "cfg_from_file('cfg/clevr_train_mac.yml')\n",
    "__C.CUDA = False\n",
    "__C.GPU_ID = '-1'\n",
    "vocab = load_vocab(cfg)\n",
    "# cfg.TRAIN.RECV_OBJECTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ClevrDataset(\n",
    "    data_dir='/Users/sebamenabar/Documents/datasets/CLEVR/data',\n",
    "    # img_dir='/Users/sebamenabar/Documents/datasets/CLEVR/CLEVR_v1.0/images/',\n",
    "    # scenes_json='/Users/sebamenabar/Documents/TAIA/individual/sm/data/clevr/train/scenes.json',\n",
    "    # raw_image=True,\n",
    "    split='val',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=ds, batch_size=2, shuffle=True,\n",
    "                                       num_workers=2, drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1677,  1.4895, -0.4643,  0.0921,  2.1208,  0.0596, -0.3440,  0.1111,\n",
       "          0.5066,  0.0738, -0.8081,  0.6521,  0.7132,  0.7500, -0.7690,  0.0585,\n",
       "          0.3345,  0.1306,  0.5794,  1.6670, -0.4928,  1.6715,  0.1323, -0.4607,\n",
       "          0.9342,  0.8394, -0.6713,  2.0152],\n",
       "        [ 0.4098,  0.7664,  0.5154, -0.2484,  1.2958,  0.8197, -0.7085, -0.8590,\n",
       "          0.1597, -0.1527, -1.0427,  1.0002,  1.4161,  0.7169, -0.0661,  0.8626,\n",
       "          1.4626,  0.2948,  0.0471,  0.9093, -1.0565,  0.4646,  0.7410, -0.8162,\n",
       "          0.3647,  0.6035, -0.1683,  2.1071]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MACNetwork(cfg=cfg, max_step=1, vocab=vocab)\n",
    "model(b['image'], b['question'], b['question_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
