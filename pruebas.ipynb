{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalMemory(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_categories=4,\n",
    "                 num_attributes_per_category=5,\n",
    "                 categories_key_size=256,\n",
    "                 attributes_key_size=256,\n",
    "                 value_size=512,\n",
    "                 dropout=0.1,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_categories = num_categories\n",
    "        self.num_attributes_per_category = num_attributes_per_category\n",
    "        \n",
    "        self.categories_key_size = categories_key_size\n",
    "        self.attributes_key_size = attributes_key_size\n",
    "        self.value_size = value_size\n",
    "        \n",
    "        self.categories = torch.FloatTensor(num_categories, categories_key_size)\n",
    "        self.attributes = torch.FloatTensor(num_categories, num_attributes_per_category, attributes_key_size)\n",
    "        \n",
    "        self.categories = nn.Parameter(self.categories)\n",
    "        self.attributes = nn.Parameter(self.attributes)\n",
    "        \n",
    "        if value_size is not None:\n",
    "            self.values = torch.FloatTensor(num_categories, num_attributes_per_category, value_size)\n",
    "            self.values = nn.Parameter(self.values)\n",
    "        else:\n",
    "            self.values = None\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self._init_params()\n",
    "        \n",
    "    def _init_params(self):\n",
    "        nn.init.normal_(self.categories)\n",
    "        nn.init.normal_(self.attributes)\n",
    "        if self.values is not None:\n",
    "            nn.init.normal_(self.values)\n",
    "        \n",
    "    def forward(self, query):\n",
    "        \n",
    "        query = self.dropout(query)\n",
    "        category_attention = torch.matmul(query[:, :self.categories_key_size], self.categories.t())\n",
    "        category_attention = nn.functional.softmax(category_attention, dim=1)\n",
    "        \n",
    "        attribute_attention = torch.matmul(self.attributes, query[:, self.categories_key_size:].t())\n",
    "        attribute_attention = nn.functional.softmax(attribute_attention.permute(2, 0, 1), dim=2)\n",
    "        \n",
    "        category_values = torch.matmul(category_attention, self.categories)\n",
    "        if self.values is not None:\n",
    "            attribute_values = (attribute_attention.unsqueeze(3) * self.values).sum(dim=2)\n",
    "        else:\n",
    "            attribute_values = (attribute_attention.unsqueeze(3) * self.attributes).sum(dim=2)\n",
    "\n",
    "        values = torch.matmul(category_attention.unsqueeze(1), attribute_values).squeeze(1)\n",
    "        \n",
    "        return values, category_values, category_attention, attribute_attention \n",
    "\n",
    "    def get_category_attention(self, query):\n",
    "        category_attention = torch.matmul(query[:, :self.categories_key_size], self.categories.t())\n",
    "        category_attention = nn.functional.softmax(category_attention, dim=1)\n",
    "\n",
    "        return category_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm = HierarchicalMemory(3, 4, 5, 6, value_size=None)\n",
    "attributes, categories = hm.attributes, hm.categories\n",
    "# print(categories), print(attributes);\n",
    "hm(torch.ones(2, 11))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mac'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3caf2af9a035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmac\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHierarchicalMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mac'"
     ]
    }
   ],
   "source": [
    "from mac import HierarchicalMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4126,  0.6920,  0.2098, -0.2235, -0.3082,  0.2059,  0.4995,\n",
       "           0.1840],\n",
       "         [-0.8027, -0.1491, -0.2894, -0.7281,  0.5694, -0.1165, -0.1300,\n",
       "          -0.0618],\n",
       "         [-0.5812,  1.0318, -0.1973, -0.1821, -0.3681, -0.3152, -0.9683,\n",
       "          -0.3389],\n",
       "         [ 0.3253,  0.0450, -0.0862, -0.0870, -0.3185,  0.1147,  0.0950,\n",
       "          -0.5925],\n",
       "         [ 0.4874, -0.6049, -0.0925,  0.0021,  0.3434,  0.9950, -0.0963,\n",
       "           0.3307]],\n",
       "\n",
       "        [[-0.4825, -0.1253, -0.1234, -0.1229,  0.3158, -0.5058, -0.2277,\n",
       "           0.6234],\n",
       "         [-1.0779, -0.6746, -0.4625,  0.3930, -0.2796, -0.1995, -0.3210,\n",
       "          -0.5292],\n",
       "         [-0.5685,  1.2189,  0.1967,  0.2939, -0.1047,  0.0913, -1.1220,\n",
       "          -0.4336],\n",
       "         [ 0.2339, -0.0343,  0.0202, -0.9019, -0.5439,  0.3890,  0.2416,\n",
       "          -0.6860],\n",
       "         [ 0.7302, -0.9310,  0.3548,  0.2108, -0.2683,  0.9025, -0.1845,\n",
       "           0.1122]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nn.functional.softmax(torch.randn(2, 5, 6), dim=2).unsqueeze(3) *  torch.randn(5, 6, 8)).sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([3, 4, 2])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1142, -0.0093,  1.2074,  0.8915, -0.6113,  0.2692],\n",
       "        [-0.0981,  1.2242, -0.0969,  0.5737,  0.4226, -0.1635]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchsummaryX import summary\n",
    "\n",
    "\n",
    "from mac import MACNetwork\n",
    "from utils import load_vocab\n",
    "from datasets import ClevrDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code/config.py:83: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "from config import cfg_from_file, __C, cfg\n",
    "\n",
    "cfg_from_file('cfg/clevr_train_mac.yml')\n",
    "__C.CUDA = False\n",
    "__C.GPU_ID = '-1'\n",
    "vocab = load_vocab(cfg)\n",
    "# cfg.TRAIN.RECV_OBJECTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ClevrDataset(\n",
    "    data_dir='/Users/sebamenabar/Documents/datasets/CLEVR/data',\n",
    "    # img_dir='/Users/sebamenabar/Documents/datasets/CLEVR/CLEVR_v1.0/images/',\n",
    "    # scenes_json='/Users/sebamenabar/Documents/TAIA/individual/sm/data/clevr/train/scenes.json',\n",
    "    # raw_image=True,\n",
    "    split='val',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=ds, batch_size=2, shuffle=True,\n",
    "                                       num_workers=2, drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0121, -0.5630,  0.8687,  0.2026, -0.2280,  0.3494, -0.1031, -0.7273,\n",
       "         -0.9819, -0.1984,  0.6235,  0.2583,  0.3696,  1.0336, -1.3561, -1.3453,\n",
       "         -0.2055, -1.2427, -0.1769, -1.0707,  0.0057, -1.0505, -0.5859,  0.4879,\n",
       "         -2.1596, -0.9108, -0.0133, -1.5043],\n",
       "        [-0.8363,  0.7582,  0.8435, -0.2574, -0.2468,  0.0294,  0.2364, -1.3489,\n",
       "         -1.3964,  0.2389, -0.0677, -1.0775,  0.7257,  1.1218, -1.3847, -0.9917,\n",
       "          1.0029, -0.7607, -0.6859,  0.2610, -0.2687, -0.7053, -1.5134,  0.3882,\n",
       "         -1.4377,  0.6135,  0.2812, -0.3642]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MACNetwork(cfg=cfg, max_step=1, vocab=vocab)\n",
    "model(b['image'], b['question'], b['question_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
